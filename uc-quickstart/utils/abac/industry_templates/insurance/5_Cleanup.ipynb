{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "340e9c9a-2673-439f-9f57-836ebf927593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83E\uDDF9 Insurance ABAC Demo - Step 5: Cleanup\n",
    "\n",
    "## \uD83D\uDCCB Overview\n",
    "This notebook cleans up all resources created during the Insurance ABAC demo, including policies, tags, tables, and schemas.\n",
    "\n",
    "### What This Notebook Does:\n",
    "1. **Drops ABAC Policies**: Removes all schema-level policies\n",
    "2. **Deletes Tag Policies**: Removes account-level tag policies\n",
    "3. **Drops Schema**: Removes the schema and all its tables\n",
    "\n",
    "### ⚠️ Warning:\n",
    "**This notebook will permanently delete:**\n",
    "- All ABAC policies on the insurance schema\n",
    "- All insurance-specific tag policies\n",
    "- The entire insurance schema and all its tables\n",
    "- All data in those tables\n",
    "\n",
    "**Only run this if you want to completely remove the demo!**\n",
    "\n",
    "## \uD83C\uDF93 How to Use This Notebook\n",
    "1. **Ensure You Want to Clean Up**: This is destructive!\n",
    "2. **Run All Cells**: Execute sequentially\n",
    "3. **Verify Cleanup**: Check that resources are removed\n",
    "\n",
    "## ⚙️ Prerequisites\n",
    "- Admin permissions to drop policies and schemas\n",
    "- Completed previous notebooks (or at least have resources to clean)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f20f29ed-308d-4a9e-a1e8-44843601a688",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml\n  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 770.3/770.3 kB 8.4 MB/s eta 0:00:00\nInstalling collected packages: pyyaml\nSuccessfully installed pyyaml-6.0.3\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install pyyaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0c4c441-4837-419b-8b40-48801d26f2ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  config.yaml not found - using defaults\n   \uD83D\uDCCA Catalog: nyounis_test\n   \uD83D\uDCC1 Schema: insurance\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \uD83D\uDCCB Load Configuration from config.yaml\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "config_file = Path('config.yaml')\n",
    "if config_file.exists():\n",
    "    with open(config_file) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    CATALOG = config['catalog']\n",
    "    SCHEMA = config['schema']\n",
    "    print(f'✅ Configuration loaded from config.yaml')\n",
    "    print(f'   \uD83D\uDCCA Catalog: {CATALOG}')\n",
    "    print(f'   \uD83D\uDCC1 Schema: {SCHEMA}')\n",
    "else:\n",
    "    # Fallback defaults\n",
    "    CATALOG = 'your_catalog_name'\n",
    "    SCHEMA = 'insurance'\n",
    "    print(f'⚠️  config.yaml not found - using defaults')\n",
    "    print(f'   \uD83D\uDCCA Catalog: {CATALOG}')\n",
    "    print(f'   \uD83D\uDCC1 Schema: {SCHEMA}')\n",
    "\n",
    "# Set catalog and schema\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b76f76e-9cd2-42a2-9c0c-39794fd20ab3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Drop All ABAC Policies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "627c22a3-3729-4110-ac16-b5783692b67b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n✅ All policies dropped successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    policies = (spark.sql(f\"SHOW POLICIES ON SCHEMA {SCHEMA}\")).collect()\n",
    "    for policy in policies:\n",
    "        policy_name = policy[\"Policy Name\"]\n",
    "        try:\n",
    "            spark.sql(f\"DROP POLICY {policy_name} ON SCHEMA {SCHEMA}\")\n",
    "            print(f\"✅ Dropped policy: {policy_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Could not drop {policy_name}: {str(e)[:40]}\")\n",
    "    print(f\"\\n✅ All policies dropped successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✅ No policies found or already cleaned up\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddd7381b-c4c8-4025-9438-e8a199fca3f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Delete Tag Policies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ee54539-9784-407a-8e62-9336366a01bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "client = WorkspaceClient()\n",
    "workspace_url = client.config.host\n",
    "\n",
    "def get_token():\n",
    "    ctx = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "    return getattr(ctx, \"apiToken\")().get()\n",
    "\n",
    "def delete_tag_policy(tag_key):\n",
    "    \"\"\"Delete a tag policy by key\"\"\"\n",
    "    try:\n",
    "        data = requests.delete(\n",
    "            f\"{workspace_url}/api/2.1/tag-policies/{tag_key}\",\n",
    "            headers={\"Authorization\": f\"Bearer {get_token()}\"}\n",
    "        )\n",
    "        if data.status_code == 200:\n",
    "            print(f\"✅ Deleted tag policy: {tag_key}\")\n",
    "        elif data.status_code == 404:\n",
    "            print(f\"ℹ️  Tag policy not found: {tag_key}\")\n",
    "        else:\n",
    "            print(f\"⚠️  Could not delete {tag_key}: {data.text}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Error deleting {tag_key}: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c633f438-64b5-4473-b1ea-99d795e39146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Deleted tag policy: pii_type_insurance\n✅ Deleted tag policy: data_classification_insurance\n\n✅ Tag policy cleanup complete\n"
     ]
    }
   ],
   "source": [
    "# Delete all insurance-specific tag policies\n",
    "delete_tag_policy('pii_type_insurance')\n",
    "delete_tag_policy('data_classification_insurance')\n",
    "\n",
    "print(\"\\n✅ Tag policy cleanup complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e57d6ea-2f77-4ef1-a42c-c1f57d6b9ef5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3: Drop Schema and All Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "228e604d-0b30-4902-b061-b41ce90b8c30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dropped schema: nyounis_test.insurance\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"DROP SCHEMA IF EXISTS {SCHEMA} CASCADE\")\n",
    "print(f\"✅ Dropped schema: {CATALOG}.{SCHEMA}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "647117a8-a7e1-46c2-b666-3fb07087a49a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ✅ Cleanup Complete!\n",
    "\n",
    "All Insurance ABAC demo resources have been removed:\n",
    "\n",
    "### What Was Deleted:\n",
    "- ✅ All ABAC policies (column masks and row filters)\n",
    "- ✅ All insurance-specific tag policies\n",
    "- ✅ Insurance schema and all tables\n",
    "- ✅ All sample data\n",
    "\n",
    "### What Remains:\n",
    "- ✅ Catalog (not deleted - may be shared across multiple schemas)\n",
    "\n",
    "### \uD83C\uDFAF Next Steps:\n",
    "\n",
    "If you want to run the demo again:\n",
    "1. Start from **`1_Create_Functions.ipynb`**\n",
    "2. Run all notebooks in sequence\n",
    "3. Everything will be recreated fresh\n",
    "\n",
    "---\n",
    "**\uD83C\uDF89 Thank you for exploring Insurance ABAC!**\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5_Cleanup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}